Web Scraping e ELT

Gostaria de compartilhar meu mais recente projeto, no qual desenvolvi um c√≥digo em Python para realizar web scraping no Mercado Livre. O objetivo principal foi criar uma base de dados bruta, permitindo a coleta das informa√ß√µes dos produtos dispon√≠veis no site.

Ap√≥s a extra√ß√£o dos dados, armazenei essas informa√ß√µes em um Data Lake fict√≠cio, explorando t√©cnicas de manipula√ß√£o de dados. Em seguida, utilizei SQL para tratar e transformar esses dados, organizando-os para facilitar a futura an√°lise em um Data Warehouse.

![Pipeline](https://github.com/user-attachments/assets/9ca482c3-2908-4da0-ad6c-110cd38603e2)

üí° Objetivos do Projeto:

Coleta de Dados: Iniciei o projeto com a extra√ß√£o de informa√ß√µes relevantes sobre os produtos do Mercado Livre. Utilizando t√©cnicas de web scraping, desenvolvi um script em Python que coleta dados dos produtos. Esse processo n√£o apenas me ajudou a entender como funciona o scraping, mas tamb√©m a import√¢ncia de uma coleta de dados bem realizada.

Cria√ß√£o de um Data Lake: Ap√≥s a coleta, os dados brutos foram armazenados em um Data Lake fict√≠cio. Constru√≠ uma pipeline visando minimizar erros e garantir que as informa√ß√µes fossem salvas de maneira eficiente. Essa etapa √© crucial, pois permite a centraliza√ß√£o dos dados em seu formato original.

![Print_DL](https://github.com/user-attachments/assets/57734e9b-12b8-477d-83a0-2880d934d62c)

Processamento de Dados: Em seguida, utilizei SQL para limpar e organizar os dados coletados. Essa fase incluiu a remo√ß√£o de duplicatas, o tratamento de valores ausentes e a transforma√ß√£o dos dados em formatos apropriados. O objetivo foi preparar essas informa√ß√µes para serem inseridas em um Data Warehouse (DW), onde estar√£o estruturadas de forma a facilitar an√°lises futuras.

![Print_DW](https://github.com/user-attachments/assets/b5fe9f57-92bb-4b69-90d0-6402dcc9038c)

An√°lise e Visualiza√ß√£o: Ap√≥s a organiza√ß√£o dos dados, estou planejando utilizar ferramentas de visualiza√ß√£o, como Tableau, para criar dashboards interativos. Isso permitir√° uma an√°lise mais simples e de f√°cil compreens√£o.

üîß Tecnologias utilizadas:

- Pandas
- SQLAlchemy
- dotenv
- Render
- DBeaver

üöÄ Pr√≥ximos passos:

Poss√≠vel integra√ß√£o com Apache Airflow para automatizar o processo de ELT.

Migra√ß√£o para Apache Spark para aumentar a efici√™ncia no processamento de dados.

Cria√ß√£o de visualiza√ß√µes no Tableau para apresentar insights de forma mais clara e limpa.

Qualquer d√∫vida ou sugest√£o, sinta-se √† vontade!
